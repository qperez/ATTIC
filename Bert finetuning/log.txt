Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
1940 BUG / 5591 NBUG 

starting creation of datasets for cross validation
creating oversampled dataset of : (5591, 2)
starting creation of datasets for cross validation
creating dataset of : (5591, 2)
starting creation of datasets for cross validation
creating undersampled dataset of : (5591, 2)
starting fine tuning
cuda:0
STARTING CROSS VALIDATION FOR NotSampled DATASET

STARTING WITH FOLD NB 0

Epoch [1/5], Step [214/2140], Train Loss: 0.5551, Valid Loss: 0.4613
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 0.4006, Valid Loss: 0.4821
Epoch [2/5], Step [642/2140], Train Loss: 0.3352, Valid Loss: 0.4008
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [2/5], Step [856/2140], Train Loss: 0.2977, Valid Loss: 0.4129
Epoch [3/5], Step [1070/2140], Train Loss: 0.1894, Valid Loss: 0.3749
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [3/5], Step [1284/2140], Train Loss: 0.2262, Valid Loss: 0.3788
Epoch [4/5], Step [1498/2140], Train Loss: 0.1194, Valid Loss: 0.5668
Epoch [4/5], Step [1712/2140], Train Loss: 0.1252, Valid Loss: 0.5263
Epoch [5/5], Step [1926/2140], Train Loss: 0.0723, Valid Loss: 0.6115
Epoch [5/5], Step [2140/2140], Train Loss: 0.0979, Valid Loss: 0.5683
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_0/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_0/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_0/model/model.pth
Pred saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_0/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.8155    0.8428    0.8289       299
           0     0.9113    0.8944    0.9028       540

    accuracy                         0.8760       839
   macro avg     0.8634    0.8686    0.8659       839
weighted avg     0.8772    0.8760    0.8765       839

STARTING WITH FOLD NB 1

Epoch [1/5], Step [214/2140], Train Loss: 0.5262, Valid Loss: 0.4697
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 0.3820, Valid Loss: 0.4111
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 0.3101, Valid Loss: 0.3950
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [2/5], Step [856/2140], Train Loss: 0.2771, Valid Loss: 0.4000
Epoch [3/5], Step [1070/2140], Train Loss: 0.1713, Valid Loss: 0.4403
Epoch [3/5], Step [1284/2140], Train Loss: 0.2104, Valid Loss: 0.3631
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [4/5], Step [1498/2140], Train Loss: 0.1107, Valid Loss: 0.4875
Epoch [4/5], Step [1712/2140], Train Loss: 0.1304, Valid Loss: 0.4134
Epoch [5/5], Step [1926/2140], Train Loss: 0.0613, Valid Loss: 0.7234
Epoch [5/5], Step [2140/2140], Train Loss: 0.0879, Valid Loss: 0.6775
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_1/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_1/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_1/model/model.pth
Pred saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_1/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.8084    0.8328    0.8204       299
           0     0.9058    0.8907    0.8982       540

    accuracy                         0.8701       839
   macro avg     0.8571    0.8618    0.8593       839
weighted avg     0.8711    0.8701    0.8705       839

STARTING WITH FOLD NB 2

Epoch [1/5], Step [214/2140], Train Loss: 0.5667, Valid Loss: 0.4363
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 0.4153, Valid Loss: 0.3831
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 0.3506, Valid Loss: 0.3379
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [2/5], Step [856/2140], Train Loss: 0.3349, Valid Loss: 0.3206
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [3/5], Step [1070/2140], Train Loss: 0.2401, Valid Loss: 0.3492
Epoch [3/5], Step [1284/2140], Train Loss: 0.2278, Valid Loss: 0.3676
Epoch [4/5], Step [1498/2140], Train Loss: 0.1523, Valid Loss: 0.3984
Epoch [4/5], Step [1712/2140], Train Loss: 0.1293, Valid Loss: 0.4469
Epoch [5/5], Step [1926/2140], Train Loss: 0.0729, Valid Loss: 0.3897
Epoch [5/5], Step [2140/2140], Train Loss: 0.0912, Valid Loss: 0.4166
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_2/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_2/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_2/model/model.pth
Pred saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_2/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7591    0.9064    0.8262       299
           0     0.9419    0.8407    0.8885       540

    accuracy                         0.8641       839
   macro avg     0.8505    0.8735    0.8573       839
weighted avg     0.8768    0.8641    0.8663       839

STARTING WITH FOLD NB 3

Epoch [1/5], Step [214/2140], Train Loss: 0.5223, Valid Loss: 0.3943
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 0.3812, Valid Loss: 0.3459
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 0.3042, Valid Loss: 0.3954
Epoch [2/5], Step [856/2140], Train Loss: 0.2810, Valid Loss: 0.3758
Epoch [3/5], Step [1070/2140], Train Loss: 0.1818, Valid Loss: 0.3759
Epoch [3/5], Step [1284/2140], Train Loss: 0.2016, Valid Loss: 0.3426
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [4/5], Step [1498/2140], Train Loss: 0.1196, Valid Loss: 0.5248
Epoch [4/5], Step [1712/2140], Train Loss: 0.1013, Valid Loss: 0.4703
Epoch [5/5], Step [1926/2140], Train Loss: 0.0690, Valid Loss: 0.5561
Epoch [5/5], Step [2140/2140], Train Loss: 0.0816, Valid Loss: 0.5498
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_3/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_3/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_3/model/model.pth
Pred saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_3/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.8231    0.8094    0.8162       299
           0     0.8954    0.9037    0.8995       540

    accuracy                         0.8701       839
   macro avg     0.8593    0.8565    0.8579       839
weighted avg     0.8697    0.8701    0.8698       839
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

STARTING WITH FOLD NB 4

Epoch [1/5], Step [214/2140], Train Loss: 0.5613, Valid Loss: 0.4485
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 0.4089, Valid Loss: 0.3489
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 0.3259, Valid Loss: 0.3363
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [2/5], Step [856/2140], Train Loss: 0.3019, Valid Loss: 0.3295
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [3/5], Step [1070/2140], Train Loss: 0.2141, Valid Loss: 0.3763
Epoch [3/5], Step [1284/2140], Train Loss: 0.2060, Valid Loss: 0.3476
Epoch [4/5], Step [1498/2140], Train Loss: 0.1264, Valid Loss: 0.3442
Epoch [4/5], Step [1712/2140], Train Loss: 0.1026, Valid Loss: 0.4270
Epoch [5/5], Step [1926/2140], Train Loss: 0.0658, Valid Loss: 0.4760
Epoch [5/5], Step [2140/2140], Train Loss: 0.0707, Valid Loss: 0.4633
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_4/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_4/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_4/model/model.pth
Pred saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_4/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7642    0.8997    0.8264       299
           0     0.9384    0.8463    0.8900       540

    accuracy                         0.8653       839
   macro avg     0.8513    0.8730    0.8582       839
weighted avg     0.8763    0.8653    0.8673       839

STARTING WITH FOLD NB 5

Epoch [1/5], Step [214/2140], Train Loss: 0.5766, Valid Loss: 0.4175
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_5/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 0.4044, Valid Loss: 0.3355
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_5/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 0.3240, Valid Loss: 0.3435
Epoch [2/5], Step [856/2140], Train Loss: 0.2944, Valid Loss: 0.2996
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_5/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [3/5], Step [1070/2140], Train Loss: 0.2207, Valid Loss: 0.3272
Epoch [3/5], Step [1284/2140], Train Loss: 0.2156, Valid Loss: 0.3059
Epoch [4/5], Step [1498/2140], Train Loss: 0.1338, Valid Loss: 0.4334
Epoch [4/5], Step [1712/2140], Train Loss: 0.1114, Valid Loss: 0.4076
Epoch [5/5], Step [1926/2140], Train Loss: 0.0802, Valid Loss: 0.4071
Epoch [5/5], Step [2140/2140], Train Loss: 0.0898, Valid Loss: 0.4782
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_5/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_5/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_5/model/model.pth
Pred saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_5/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.8106    0.8161    0.8133       299
           0     0.8978    0.8944    0.8961       540

    accuracy                         0.8665       839
   macro avg     0.8542    0.8552    0.8547       839
weighted avg     0.8667    0.8665    0.8666       839

STARTING WITH FOLD NB 6

Epoch [1/5], Step [214/2140], Train Loss: 0.5616, Valid Loss: 0.4122
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_6/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_6/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 0.4013, Valid Loss: 0.3413
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_6/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_6/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 0.3051, Valid Loss: 0.3447
Epoch [2/5], Step [856/2140], Train Loss: 0.2853, Valid Loss: 0.3422
Epoch [3/5], Step [1070/2140], Train Loss: 0.1857, Valid Loss: 0.4410
Epoch [3/5], Step [1284/2140], Train Loss: 0.2050, Valid Loss: 0.3586
Epoch [4/5], Step [1498/2140], Train Loss: 0.1299, Valid Loss: 0.5467
Epoch [4/5], Step [1712/2140], Train Loss: 0.1099, Valid Loss: 0.5515
Epoch [5/5], Step [1926/2140], Train Loss: 0.0733, Valid Loss: 0.3839
Epoch [5/5], Step [2140/2140], Train Loss: 0.0709, Valid Loss: 0.4868
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_6/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_6/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_6/model/model.pth
Pred saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_6/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7950    0.8562    0.8245       299
           0     0.9168    0.8778    0.8969       540

    accuracy                         0.8701       839
   macro avg     0.8559    0.8670    0.8607       839
weighted avg     0.8734    0.8701    0.8711       839

STARTING WITH FOLD NB 7

Epoch [1/5], Step [214/2140], Train Loss: 0.6552, Valid Loss: 0.6682
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_7/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 0.6512, Valid Loss: 0.6632
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_7/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 0.6540, Valid Loss: 0.6789
Epoch [2/5], Step [856/2140], Train Loss: 0.6448, Valid Loss: 0.6737
Epoch [3/5], Step [1070/2140], Train Loss: 0.6443, Valid Loss: 0.6781
Epoch [3/5], Step [1284/2140], Train Loss: 0.6541, Valid Loss: 0.6659
Epoch [4/5], Step [1498/2140], Train Loss: 0.6460, Valid Loss: 0.6673
Epoch [4/5], Step [1712/2140], Train Loss: 0.6483, Valid Loss: 0.6637
Epoch [5/5], Step [1926/2140], Train Loss: 0.6477, Valid Loss: 0.6712
Epoch [5/5], Step [2140/2140], Train Loss: 0.6480, Valid Loss: 0.6626
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_7/metrics/metrics.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_7/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_7/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_7/model/model.pth
Pred saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_7/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.0000    0.0000    0.0000       299
           0     0.6436    1.0000    0.7832       540

    accuracy                         0.6436       839
   macro avg     0.3218    0.5000    0.3916       839
weighted avg     0.4143    0.6436    0.5041       839

STARTING WITH FOLD NB 8

Epoch [1/5], Step [214/2140], Train Loss: 0.6580, Valid Loss: 0.6275
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_8/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_8/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 0.6532, Valid Loss: 0.6337
Epoch [2/5], Step [642/2140], Train Loss: 0.6559, Valid Loss: 0.6331
Epoch [2/5], Step [856/2140], Train Loss: 0.6462, Valid Loss: 0.6275
Epoch [3/5], Step [1070/2140], Train Loss: 0.6512, Valid Loss: 0.6098
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_8/model/model.pthSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_8/metrics/metrics.pth
Epoch [3/5], Step [1284/2140], Train Loss: 0.6572, Valid Loss: 0.6329
Epoch [4/5], Step [1498/2140], Train Loss: 0.6543, Valid Loss: 0.6373
Epoch [4/5], Step [1712/2140], Train Loss: 0.6475, Valid Loss: 0.6321
Epoch [5/5], Step [1926/2140], Train Loss: 0.6488, Valid Loss: 0.6290
Epoch [5/5], Step [2140/2140], Train Loss: 0.6468, Valid Loss: 0.6307
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_8/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_8/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_8/model/model.pth
Pred saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_8/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.0000    0.0000    0.0000       299
           0     0.6432    0.9981    0.7823       540

    accuracy                         0.6424       839
   macro avg     0.3216    0.4991    0.3911       839
weighted avg     0.4140    0.6424    0.5035       839

STARTING WITH FOLD NB 9

Epoch [1/5], Step [214/2140], Train Loss: 0.6611, Valid Loss: 0.6018
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_9/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_9/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 0.4908, Valid Loss: 0.3630
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_9/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_9/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 0.3422, Valid Loss: 0.3804
Epoch [2/5], Step [856/2140], Train Loss: 0.3158, Valid Loss: 0.3566
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_9/model/model.pth
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_9/metrics/metrics.pth
Epoch [3/5], Step [1070/2140], Train Loss: 0.2092, Valid Loss: 0.4093
Epoch [3/5], Step [1284/2140], Train Loss: 0.2060, Valid Loss: 0.4234
Epoch [4/5], Step [1498/2140], Train Loss: 0.1130, Valid Loss: 0.4374
Epoch [4/5], Step [1712/2140], Train Loss: 0.1217, Valid Loss: 0.4864
Epoch [5/5], Step [1926/2140], Train Loss: 0.0539, Valid Loss: 0.6817
Epoch [5/5], Step [2140/2140], Train Loss: 0.0883, Valid Loss: 0.5255
Model saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_9/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_9/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/NotSampled/Dataset_KFold_9/model/model.pth
Pred saved to ==> Temp_Data_Files/NotSampled/Dataset_KFold_9/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.8628    0.7993    0.8299       299
           0     0.8932    0.9296    0.9111       540

    accuracy                         0.8832       839
   macro avg     0.8780    0.8645    0.8705       839
weighted avg     0.8824    0.8832    0.8821       839

STARTING CROSS VALIDATION FOR UnderSampled DATASET

STARTING WITH FOLD NB 0

Epoch [1/5], Step [146/1465], Train Loss: 0.6994, Valid Loss: 0.6590
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [1/5], Step [292/1465], Train Loss: 0.5011, Valid Loss: 0.4382
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [2/5], Step [438/1465], Train Loss: 0.3773, Valid Loss: 0.3997
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [2/5], Step [584/1465], Train Loss: 0.3426, Valid Loss: 0.3934
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [3/5], Step [730/1465], Train Loss: 0.2375, Valid Loss: 0.3993
Epoch [3/5], Step [876/1465], Train Loss: 0.2359, Valid Loss: 0.4025
Epoch [4/5], Step [1022/1465], Train Loss: 0.1363, Valid Loss: 0.6128
Epoch [4/5], Step [1168/1465], Train Loss: 0.1470, Valid Loss: 0.4200
Epoch [5/5], Step [1314/1465], Train Loss: 0.0984, Valid Loss: 0.4925
Epoch [5/5], Step [1460/1465], Train Loss: 0.0847, Valid Loss: 0.7110
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_0/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_0/model/model.pth
Pred saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7576    0.9197    0.8308       299
           0     0.9496    0.8370    0.8898       540

    accuracy                         0.8665       839
   macro avg     0.8536    0.8784    0.8603       839
weighted avg     0.8812    0.8665    0.8688       839

STARTING WITH FOLD NB 1

Epoch [1/5], Step [148/1480], Train Loss: 0.7008, Valid Loss: 0.7120
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [1/5], Step [296/1480], Train Loss: 0.7007, Valid Loss: 0.6894
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [2/5], Step [444/1480], Train Loss: 0.6995, Valid Loss: 0.6888
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [2/5], Step [592/1480], Train Loss: 0.6999, Valid Loss: 0.6637
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [3/5], Step [740/1480], Train Loss: 0.7000, Valid Loss: 0.7145
Epoch [3/5], Step [888/1480], Train Loss: 0.7009, Valid Loss: 0.6989
Epoch [4/5], Step [1036/1480], Train Loss: 0.7012, Valid Loss: 0.6712
Epoch [4/5], Step [1184/1480], Train Loss: 0.6982, Valid Loss: 0.7100
Epoch [5/5], Step [1332/1480], Train Loss: 0.6991, Valid Loss: 0.6704
Epoch [5/5], Step [1480/1480], Train Loss: 0.7022, Valid Loss: 0.7041
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_1/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_1/model/model.pth
Pred saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.0000    0.0000    0.0000       299
           0     0.6436    1.0000    0.7832       540

    accuracy                         0.6436       839
   macro avg     0.3218    0.5000    0.3916       839
weighted avg     0.4143    0.6436    0.5041       839

Traceback (most recent call last):
  File "Bert_Fine_Tuning_CV10_NS_US_OS_summary.py", line 479, in <module>
    cross_val(training_path, 'UnderSampled')
  File "Bert_Fine_Tuning_CV10_NS_US_OS_summary.py", line 474, in cross_val
    evaluate(model=best_model, test_loader=test_iter,
  File "Bert_Fine_Tuning_CV10_NS_US_OS_summary.py", line 437, in evaluate
    ax.xaxis.set_ticklabels(['NBug', 'Bug'])
  File "/home/equipe1/.local/lib/python3.8/site-packages/matplotlib/axis.py", line 1717, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of ticklabels (2).
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
1940 BUG / 5591 NBUG 

starting creation of datasets for cross validation
creating oversampled dataset of : (5591, 2)
starting creation of datasets for cross validation
creating dataset of : (5591, 2)
starting creation of datasets for cross validation
creating undersampled dataset of : (5591, 2)
starting fine tuning
cuda:0
STARTING CROSS VALIDATION FOR UnderSampled DATASET

STARTING WITH FOLD NB 0

Epoch [1/5], Step [146/1465], Train Loss: 0.6873, Valid Loss: 0.6800
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [1/5], Step [292/1465], Train Loss: 0.4695, Valid Loss: 0.4961
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [2/5], Step [438/1465], Train Loss: 0.3524, Valid Loss: 0.4243
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [2/5], Step [584/1465], Train Loss: 0.3541, Valid Loss: 0.4149
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [3/5], Step [730/1465], Train Loss: 0.2260, Valid Loss: 0.4945
Epoch [3/5], Step [876/1465], Train Loss: 0.2335, Valid Loss: 0.3865
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [4/5], Step [1022/1465], Train Loss: 0.1354, Valid Loss: 0.4573
Epoch [4/5], Step [1168/1465], Train Loss: 0.1190, Valid Loss: 0.6792
Epoch [5/5], Step [1314/1465], Train Loss: 0.0784, Valid Loss: 0.6043
Epoch [5/5], Step [1460/1465], Train Loss: 0.0903, Valid Loss: 0.4870
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_0/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_0/model/model.pth
Pred saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_0/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7759    0.9030    0.8346       299
           0     0.9409    0.8556    0.8962       540

    accuracy                         0.8725       839
   macro avg     0.8584    0.8793    0.8654       839
weighted avg     0.8821    0.8725    0.8743       839

STARTING WITH FOLD NB 1

Epoch [1/5], Step [148/1480], Train Loss: 0.7046, Valid Loss: 0.6968
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [1/5], Step [296/1480], Train Loss: 0.6510, Valid Loss: 0.5194
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [2/5], Step [444/1480], Train Loss: 0.4053, Valid Loss: 0.4166
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [2/5], Step [592/1480], Train Loss: 0.3810, Valid Loss: 0.3762
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [3/5], Step [740/1480], Train Loss: 0.2625, Valid Loss: 0.3892
Epoch [3/5], Step [888/1480], Train Loss: 0.2594, Valid Loss: 0.4304
Epoch [4/5], Step [1036/1480], Train Loss: 0.1710, Valid Loss: 0.5110
Epoch [4/5], Step [1184/1480], Train Loss: 0.1370, Valid Loss: 0.6228
Epoch [5/5], Step [1332/1480], Train Loss: 0.0729, Valid Loss: 0.6283
Epoch [5/5], Step [1480/1480], Train Loss: 0.1000, Valid Loss: 0.4929
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_1/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_1/model/model.pth
Pred saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_1/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7377    0.9030    0.8120       299
           0     0.9387    0.8222    0.8766       540

    accuracy                         0.8510       839
   macro avg     0.8382    0.8626    0.8443       839
weighted avg     0.8671    0.8510    0.8536       839

STARTING WITH FOLD NB 2

Epoch [1/5], Step [148/1480], Train Loss: 0.7115, Valid Loss: 0.7062
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [1/5], Step [296/1480], Train Loss: 0.7047, Valid Loss: 0.6697
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [2/5], Step [444/1480], Train Loss: 0.7053, Valid Loss: 0.7228
Epoch [2/5], Step [592/1480], Train Loss: 0.7054, Valid Loss: 0.6736
Epoch [3/5], Step [740/1480], Train Loss: 0.6991, Valid Loss: 0.6979
Epoch [3/5], Step [888/1480], Train Loss: 0.6969, Valid Loss: 0.6582
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [4/5], Step [1036/1480], Train Loss: 0.7013, Valid Loss: 0.6964
Epoch [4/5], Step [1184/1480], Train Loss: 0.6984, Valid Loss: 0.6955
Epoch [5/5], Step [1332/1480], Train Loss: 0.6783, Valid Loss: 0.6955
Epoch [5/5], Step [1480/1480], Train Loss: 0.7050, Valid Loss: 0.7219
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_2/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_2/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_2/model/model.pth
Pred saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_2/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.0000    0.0000    0.0000       299
           0     0.6436    1.0000    0.7832       540

    accuracy                         0.6436       839
   macro avg     0.3218    0.5000    0.3916       839
weighted avg     0.4143    0.6436    0.5041       839

STARTING WITH FOLD NB 3

Epoch [1/5], Step [148/1485], Train Loss: 0.6994, Valid Loss: 0.7162
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [1/5], Step [296/1485], Train Loss: 0.6851, Valid Loss: 0.6791
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [2/5], Step [444/1485], Train Loss: 0.5131, Valid Loss: 0.4487
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [2/5], Step [592/1485], Train Loss: 0.4486, Valid Loss: 0.4356
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [3/5], Step [740/1485], Train Loss: 0.3531, Valid Loss: 0.4230
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [3/5], Step [888/1485], Train Loss: 0.3307, Valid Loss: 0.3879
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [4/5], Step [1036/1485], Train Loss: 0.2261, Valid Loss: 0.4680
Epoch [4/5], Step [1184/1485], Train Loss: 0.2339, Valid Loss: 0.4346
Epoch [5/5], Step [1332/1485], Train Loss: 0.1307, Valid Loss: 0.5217Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Epoch [5/5], Step [1480/1485], Train Loss: 0.1651, Valid Loss: 0.5009
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_3/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_3/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_3/model/model.pth
Pred saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_3/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7350    0.8997    0.8090       299
           0     0.9366    0.8204    0.8746       540

    accuracy                         0.8486       839
   macro avg     0.8358    0.8600    0.8418       839
weighted avg     0.8647    0.8486    0.8512       839

STARTING WITH FOLD NB 4

Epoch [1/5], Step [147/1470], Train Loss: 0.7032, Valid Loss: 0.7532
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [1/5], Step [294/1470], Train Loss: 0.7062, Valid Loss: 0.7426
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [2/5], Step [441/1470], Train Loss: 0.6983, Valid Loss: 0.7017
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [2/5], Step [588/1470], Train Loss: 0.6962, Valid Loss: 0.7210
Epoch [3/5], Step [735/1470], Train Loss: 0.7041, Valid Loss: 0.7015
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [3/5], Step [882/1470], Train Loss: 0.6874, Valid Loss: 0.6804
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [4/5], Step [1029/1470], Train Loss: 0.6361, Valid Loss: 0.5621
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [4/5], Step [1176/1470], Train Loss: 0.5146, Valid Loss: 0.4662
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [5/5], Step [1323/1470], Train Loss: 0.4717, Valid Loss: 0.4798
Epoch [5/5], Step [1470/1470], Train Loss: 0.4192, Valid Loss: 0.4369
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/metrics/metrics.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_4/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_4/model/model.pth
Pred saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_4/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.6550    0.9398    0.7720       299
           0     0.9561    0.7259    0.8253       540

    accuracy                         0.8021       839
   macro avg     0.8056    0.8329    0.7986       839
weighted avg     0.8488    0.8021    0.8063       839

STARTING WITH FOLD NB 5

Epoch [1/5], Step [147/1470], Train Loss: 0.6969, Valid Loss: 0.6788
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_5/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [1/5], Step [294/1470], Train Loss: 0.4706, Valid Loss: 0.3883
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_5/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [2/5], Step [441/1470], Train Loss: 0.3571, Valid Loss: 0.3620
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_5/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [2/5], Step [588/1470], Train Loss: 0.3458, Valid Loss: 0.3052
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_5/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [3/5], Step [735/1470], Train Loss: 0.2249, Valid Loss: 0.3479
Epoch [3/5], Step [882/1470], Train Loss: 0.2090, Valid Loss: 0.3500
Epoch [4/5], Step [1029/1470], Train Loss: 0.1215, Valid Loss: 0.4384
Epoch [4/5], Step [1176/1470], Train Loss: 0.1580, Valid Loss: 0.3600
Epoch [5/5], Step [1323/1470], Train Loss: 0.0716, Valid Loss: 0.5808
Epoch [5/5], Step [1470/1470], Train Loss: 0.0845, Valid Loss: 0.4225
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_5/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_5/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_5/model/model.pth
Pred saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_5/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7734    0.9130    0.8374       299
           0     0.9465    0.8519    0.8967       540

    accuracy                         0.8737       839
   macro avg     0.8599    0.8824    0.8671       839
weighted avg     0.8848    0.8737    0.8756       839

STARTING WITH FOLD NB 6

Epoch [1/5], Step [147/1475], Train Loss: 0.5527, Valid Loss: 0.3594
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_6/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_6/metrics/metrics.pth
Epoch [1/5], Step [294/1475], Train Loss: 0.3949, Valid Loss: 0.3565
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_6/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_6/metrics/metrics.pth
Epoch [2/5], Step [441/1475], Train Loss: 0.3199, Valid Loss: 0.3394
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_6/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_6/metrics/metrics.pth
Epoch [2/5], Step [588/1475], Train Loss: 0.3023, Valid Loss: 0.3352
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_6/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_6/metrics/metrics.pth
Epoch [3/5], Step [735/1475], Train Loss: 0.1913, Valid Loss: 0.5182
Epoch [3/5], Step [882/1475], Train Loss: 0.2155, Valid Loss: 0.3720
Epoch [4/5], Step [1029/1475], Train Loss: 0.0967, Valid Loss: 0.4158
Epoch [4/5], Step [1176/1475], Train Loss: 0.1147, Valid Loss: 0.4702
Epoch [5/5], Step [1323/1475], Train Loss: 0.0555, Valid Loss: 0.5278
Epoch [5/5], Step [1470/1475], Train Loss: 0.0994, Valid Loss: 0.5973
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_6/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_6/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_6/model/model.pth
Pred saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_6/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7305    0.9064    0.8090       299
           0     0.9402    0.8148    0.8730       540

    accuracy                         0.8474       839
   macro avg     0.8353    0.8606    0.8410       839
weighted avg     0.8654    0.8474    0.8502       839

STARTING WITH FOLD NB 7

Epoch [1/5], Step [146/1465], Train Loss: 0.6996, Valid Loss: 0.6901
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_7/metrics/metrics.pth
Epoch [1/5], Step [292/1465], Train Loss: 0.6123, Valid Loss: 0.4474
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_7/metrics/metrics.pth
Epoch [2/5], Step [438/1465], Train Loss: 0.4400, Valid Loss: 0.4191Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_7/metrics/metrics.pth
Epoch [2/5], Step [584/1465], Train Loss: 0.3826, Valid Loss: 0.3798
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_7/metrics/metrics.pth
Epoch [3/5], Step [730/1465], Train Loss: 0.2848, Valid Loss: 0.3814
Epoch [3/5], Step [876/1465], Train Loss: 0.2760, Valid Loss: 0.3568
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_7/metrics/metrics.pth
Epoch [4/5], Step [1022/1465], Train Loss: 0.1743, Valid Loss: 0.4569
Epoch [4/5], Step [1168/1465], Train Loss: 0.1992, Valid Loss: 0.3952
Epoch [5/5], Step [1314/1465], Train Loss: 0.0953, Valid Loss: 0.4679
Epoch [5/5], Step [1460/1465], Train Loss: 0.1305, Valid Loss: 0.5075
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_7/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_7/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_7/model/model.pth
Pred saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_7/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7401    0.9331    0.8254       299
           0     0.9567    0.8185    0.8822       540

    accuracy                         0.8594       839
   macro avg     0.8484    0.8758    0.8538       839
weighted avg     0.8795    0.8594    0.8620       839

STARTING WITH FOLD NB 8

Epoch [1/5], Step [149/1490], Train Loss: 0.6086, Valid Loss: 0.4340
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_8/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_8/metrics/metrics.pth
Epoch [1/5], Step [298/1490], Train Loss: 0.4272, Valid Loss: 0.4058
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_8/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_8/metrics/metrics.pth
Epoch [2/5], Step [447/1490], Train Loss: 0.3324, Valid Loss: 0.4227
Epoch [2/5], Step [596/1490], Train Loss: 0.3099, Valid Loss: 0.3496
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_8/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_8/metrics/metrics.pth
Epoch [3/5], Step [745/1490], Train Loss: 0.1833, Valid Loss: 0.4397
Epoch [3/5], Step [894/1490], Train Loss: 0.2139, Valid Loss: 0.3801
Epoch [4/5], Step [1043/1490], Train Loss: 0.1296, Valid Loss: 0.5992
Epoch [4/5], Step [1192/1490], Train Loss: 0.1255, Valid Loss: 0.4358
Epoch [5/5], Step [1341/1490], Train Loss: 0.0848, Valid Loss: 0.5028
Epoch [5/5], Step [1490/1490], Train Loss: 0.1071, Valid Loss: 0.4689
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_8/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_8/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_8/model/model.pth
Pred saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_8/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.8000    0.8562    0.8271       299
           0     0.9171    0.8815    0.8990       540

    accuracy                         0.8725       839
   macro avg     0.8586    0.8688    0.8631       839
weighted avg     0.8754    0.8725    0.8734       839

STARTING WITH FOLD NB 9

Epoch [1/5], Step [151/1515], Train Loss: 0.6491, Valid Loss: 0.4107
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_9/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_9/metrics/metrics.pth
Epoch [1/5], Step [302/1515], Train Loss: 0.4490, Valid Loss: 0.3922
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_9/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_9/metrics/metrics.pth
Epoch [2/5], Step [453/1515], Train Loss: 0.3502, Valid Loss: 0.4565
Epoch [2/5], Step [604/1515], Train Loss: 0.3277, Valid Loss: 0.3608
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_9/model/model.pth
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_9/metrics/metrics.pth
Epoch [3/5], Step [755/1515], Train Loss: 0.2258, Valid Loss: 0.3616
Epoch [3/5], Step [906/1515], Train Loss: 0.2289, Valid Loss: 0.5277
Epoch [4/5], Step [1057/1515], Train Loss: 0.1507, Valid Loss: 0.5316
Epoch [4/5], Step [1208/1515], Train Loss: 0.1628, Valid Loss: 0.4779
Epoch [5/5], Step [1359/1515], Train Loss: 0.0828, Valid Loss: 0.5564
Epoch [5/5], Step [1510/1515], Train Loss: 0.0900, Valid Loss: 0.5100
Model saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_9/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_9/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/UnderSampled/Dataset_KFold_9/model/model.pth
Pred saved to ==> Temp_Data_Files/UnderSampled/Dataset_KFold_9/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7938    0.8629    0.8269       299
           0     0.9202    0.8759    0.8975       540

    accuracy                         0.8713       839
   macro avg     0.8570    0.8694    0.8622       839
weighted avg     0.8752    0.8713    0.8724       839

STARTING CROSS VALIDATION FOR OverSampled DATASET

STARTING WITH FOLD NB 0

Epoch [1/5], Step [281/2815], Train Loss: 0.7006, Valid Loss: 0.7142
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [1/5], Step [562/2815], Train Loss: 0.7035, Valid Loss: 0.6664
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [2/5], Step [843/2815], Train Loss: 0.6295, Valid Loss: 0.5472
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [2/5], Step [1124/2815], Train Loss: 0.6017, Valid Loss: 0.6381
Epoch [3/5], Step [1405/2815], Train Loss: 0.5434, Valid Loss: 0.6156
Epoch [3/5], Step [1686/2815], Train Loss: 0.4671, Valid Loss: 0.4643
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [4/5], Step [1967/2815], Train Loss: 0.3842, Valid Loss: 0.4990
Epoch [4/5], Step [2248/2815], Train Loss: 0.3618, Valid Loss: 0.4818
Epoch [5/5], Step [2529/2815], Train Loss: 0.2967, Valid Loss: 0.4812
Epoch [5/5], Step [2810/2815], Train Loss: 0.2565, Valid Loss: 0.5048
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_0/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_0/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_0/model/model.pth
Pred saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_0/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7281    0.8328    0.7769       299
           0     0.8994    0.8278    0.8621       540

    accuracy                         0.8296       839
   macro avg     0.8137    0.8303    0.8195       839
weighted avg     0.8383    0.8296    0.8317       839

STARTING WITH FOLD NB 1

Epoch [1/5], Step [280/2800], Train Loss: 0.5645, Valid Loss: 0.4039
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [1/5], Step [560/2800], Train Loss: 0.3800, Valid Loss: 0.3952
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [2/5], Step [840/2800], Train Loss: 0.2600, Valid Loss: 0.4074Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Epoch [2/5], Step [1120/2800], Train Loss: 0.2439, Valid Loss: 0.4355
Epoch [3/5], Step [1400/2800], Train Loss: 0.1265, Valid Loss: 0.4221
Epoch [3/5], Step [1680/2800], Train Loss: 0.1472, Valid Loss: 0.4941
Epoch [4/5], Step [1960/2800], Train Loss: 0.0699, Valid Loss: 0.6097
Epoch [4/5], Step [2240/2800], Train Loss: 0.0751, Valid Loss: 0.6316
Epoch [5/5], Step [2520/2800], Train Loss: 0.0446, Valid Loss: 0.6806
Epoch [5/5], Step [2800/2800], Train Loss: 0.0418, Valid Loss: 0.5332
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_1/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_1/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_1/model/model.pth
Pred saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_1/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7542    0.8930    0.8178       299
           0     0.9340    0.8389    0.8839       540

    accuracy                         0.8582       839
   macro avg     0.8441    0.8659    0.8508       839
weighted avg     0.8700    0.8582    0.8603       839

STARTING WITH FOLD NB 2

Epoch [1/5], Step [280/2800], Train Loss: 0.5926, Valid Loss: 0.4020
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [1/5], Step [560/2800], Train Loss: 0.3942, Valid Loss: 0.3643
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [2/5], Step [840/2800], Train Loss: 0.2712, Valid Loss: 0.3528
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [2/5], Step [1120/2800], Train Loss: 0.2661, Valid Loss: 0.3749
Epoch [3/5], Step [1400/2800], Train Loss: 0.1578, Valid Loss: 0.4579
Epoch [3/5], Step [1680/2800], Train Loss: 0.1479, Valid Loss: 0.4103
Epoch [4/5], Step [1960/2800], Train Loss: 0.1067, Valid Loss: 0.4423
Epoch [4/5], Step [2240/2800], Train Loss: 0.0877, Valid Loss: 0.4988
Epoch [5/5], Step [2520/2800], Train Loss: 0.0481, Valid Loss: 0.5336
Epoch [5/5], Step [2800/2800], Train Loss: 0.0553, Valid Loss: 0.5144
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_2/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_2/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_2/model/model.pth
Pred saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_2/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7240    0.9298    0.8141       299
           0     0.9538    0.8037    0.8724       540

    accuracy                         0.8486       839
   macro avg     0.8389    0.8667    0.8432       839
weighted avg     0.8719    0.8486    0.8516       839

STARTING WITH FOLD NB 3

Epoch [1/5], Step [280/2800], Train Loss: 0.4986, Valid Loss: 0.4154
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [1/5], Step [560/2800], Train Loss: 0.3696, Valid Loss: 0.3935
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [2/5], Step [840/2800], Train Loss: 0.2394, Valid Loss: 0.3635
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [2/5], Step [1120/2800], Train Loss: 0.2599, Valid Loss: 0.3278
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [3/5], Step [1400/2800], Train Loss: 0.1401, Valid Loss: 0.5053
Epoch [3/5], Step [1680/2800], Train Loss: 0.1405, Valid Loss: 0.4151
Epoch [4/5], Step [1960/2800], Train Loss: 0.0810, Valid Loss: 0.4500
Epoch [4/5], Step [2240/2800], Train Loss: 0.0764, Valid Loss: 0.4576
Epoch [5/5], Step [2520/2800], Train Loss: 0.0511, Valid Loss: 0.6024
Epoch [5/5], Step [2800/2800], Train Loss: 0.0325, Valid Loss: 0.5941
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_3/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_3/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_3/model/model.pth
Pred saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_3/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.8345    0.8261    0.8303       299
           0     0.9042    0.9093    0.9067       540

    accuracy                         0.8796       839
   macro avg     0.8693    0.8677    0.8685       839
weighted avg     0.8794    0.8796    0.8795       839

STARTING WITH FOLD NB 4

Epoch [1/5], Step [281/2810], Train Loss: 0.5460, Valid Loss: 0.4047
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [1/5], Step [562/2810], Train Loss: 0.3537, Valid Loss: 0.3984
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [2/5], Step [843/2810], Train Loss: 0.2618, Valid Loss: 0.3414
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [2/5], Step [1124/2810], Train Loss: 0.2403, Valid Loss: 0.4004
Epoch [3/5], Step [1405/2810], Train Loss: 0.1412, Valid Loss: 0.3854
Epoch [3/5], Step [1686/2810], Train Loss: 0.1323, Valid Loss: 0.4152
Epoch [4/5], Step [1967/2810], Train Loss: 0.0721, Valid Loss: 0.5119
Epoch [4/5], Step [2248/2810], Train Loss: 0.0912, Valid Loss: 0.4913
Epoch [5/5], Step [2529/2810], Train Loss: 0.0680, Valid Loss: 0.4797
Epoch [5/5], Step [2810/2810], Train Loss: 0.0655, Valid Loss: 0.5213
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_4/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_4/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_4/model/model.pth
Pred saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_4/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.8006    0.8595    0.8290       299
           0     0.9189    0.8815    0.8998       540

    accuracy                         0.8737       839
   macro avg     0.8598    0.8705    0.8644       839
weighted avg     0.8768    0.8737    0.8746       839

STARTING WITH FOLD NB 5

Epoch [1/5], Step [281/2810], Train Loss: 0.5746, Valid Loss: 0.3822
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_5/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [1/5], Step [562/2810], Train Loss: 0.3717, Valid Loss: 0.3142
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_5/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [2/5], Step [843/2810], Train Loss: 0.2680, Valid Loss: 0.3129
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_5/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [2/5], Step [1124/2810], Train Loss: 0.2434, Valid Loss: 0.3167
Epoch [3/5], Step [1405/2810], Train Loss: 0.1264, Valid Loss: 0.3979
Epoch [3/5], Step [1686/2810], Train Loss: 0.1419, Valid Loss: 0.3905
Epoch [4/5], Step [1967/2810], Train Loss: 0.0706, Valid Loss: 0.4082
Epoch [4/5], Step [2248/2810], Train Loss: 0.0686, Valid Loss: 0.4642
Epoch [5/5], Step [2529/2810], Train Loss: 0.0340, Valid Loss: 0.5216Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Epoch [5/5], Step [2810/2810], Train Loss: 0.0484, Valid Loss: 0.5104
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_5/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_5/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_5/model/model.pth
Pred saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_5/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.8317    0.8428    0.8372       299
           0     0.9123    0.9056    0.9089       540

    accuracy                         0.8832       839
   macro avg     0.8720    0.8742    0.8731       839
weighted avg     0.8836    0.8832    0.8834       839

STARTING WITH FOLD NB 6

Epoch [1/5], Step [280/2805], Train Loss: 0.6375, Valid Loss: 0.4064
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_6/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_6/metrics/metrics.pth
Epoch [1/5], Step [560/2805], Train Loss: 0.3806, Valid Loss: 0.3362
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_6/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_6/metrics/metrics.pth
Epoch [2/5], Step [840/2805], Train Loss: 0.2689, Valid Loss: 0.3408
Epoch [2/5], Step [1120/2805], Train Loss: 0.2341, Valid Loss: 0.3166
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_6/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_6/metrics/metrics.pth
Epoch [3/5], Step [1400/2805], Train Loss: 0.1243, Valid Loss: 0.3384
Epoch [3/5], Step [1680/2805], Train Loss: 0.1239, Valid Loss: 0.4220
Epoch [4/5], Step [1960/2805], Train Loss: 0.0642, Valid Loss: 0.4418
Epoch [4/5], Step [2240/2805], Train Loss: 0.0822, Valid Loss: 0.4570
Epoch [5/5], Step [2520/2805], Train Loss: 0.0465, Valid Loss: 0.5608
Epoch [5/5], Step [2800/2805], Train Loss: 0.0418, Valid Loss: 0.4773
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_6/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_6/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_6/model/model.pth
Pred saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_6/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.8557    0.8528    0.8543       299
           0     0.9187    0.9204    0.9195       540

    accuracy                         0.8963       839
   macro avg     0.8872    0.8866    0.8869       839
weighted avg     0.8962    0.8963    0.8963       839

STARTING WITH FOLD NB 7

Epoch [1/5], Step [281/2815], Train Loss: 0.5732, Valid Loss: 0.4053
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_7/metrics/metrics.pth
Epoch [1/5], Step [562/2815], Train Loss: 0.3870, Valid Loss: 0.3574
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_7/metrics/metrics.pth
Epoch [2/5], Step [843/2815], Train Loss: 0.2751, Valid Loss: 0.3172
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_7/metrics/metrics.pth
Epoch [2/5], Step [1124/2815], Train Loss: 0.2515, Valid Loss: 0.3786
Epoch [3/5], Step [1405/2815], Train Loss: 0.1416, Valid Loss: 0.5829
Epoch [3/5], Step [1686/2815], Train Loss: 0.1417, Valid Loss: 0.4788
Epoch [4/5], Step [1967/2815], Train Loss: 0.0752, Valid Loss: 0.5021
Epoch [4/5], Step [2248/2815], Train Loss: 0.0837, Valid Loss: 0.5008
Epoch [5/5], Step [2529/2815], Train Loss: 0.0433, Valid Loss: 0.6110
Epoch [5/5], Step [2810/2815], Train Loss: 0.0499, Valid Loss: 0.7540
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_7/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_7/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_7/model/model.pth
Pred saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_7/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.8179    0.8261    0.8220       299
           0     0.9032    0.8981    0.9006       540

    accuracy                         0.8725       839
   macro avg     0.8605    0.8621    0.8613       839
weighted avg     0.8728    0.8725    0.8726       839

STARTING WITH FOLD NB 8

Epoch [1/5], Step [279/2790], Train Loss: 0.6100, Valid Loss: 0.3951
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_8/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_8/metrics/metrics.pth
Epoch [1/5], Step [558/2790], Train Loss: 0.4024, Valid Loss: 0.3576
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_8/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_8/metrics/metrics.pth
Epoch [2/5], Step [837/2790], Train Loss: 0.2878, Valid Loss: 0.3520
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_8/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_8/metrics/metrics.pth
Epoch [2/5], Step [1116/2790], Train Loss: 0.2644, Valid Loss: 0.3687
Epoch [3/5], Step [1395/2790], Train Loss: 0.1658, Valid Loss: 0.4104
Epoch [3/5], Step [1674/2790], Train Loss: 0.1601, Valid Loss: 0.3288
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_8/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_8/metrics/metrics.pth
Epoch [4/5], Step [1953/2790], Train Loss: 0.0903, Valid Loss: 0.3486
Epoch [4/5], Step [2232/2790], Train Loss: 0.0946, Valid Loss: 0.5185
Epoch [5/5], Step [2511/2790], Train Loss: 0.0656, Valid Loss: 0.4363
Epoch [5/5], Step [2790/2790], Train Loss: 0.0632, Valid Loss: 0.4730
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_8/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_8/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_8/model/model.pth
Pred saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_8/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.8056    0.8595    0.8317       299
           0     0.9192    0.8852    0.9019       540

    accuracy                         0.8760       839
   macro avg     0.8624    0.8724    0.8668       839
weighted avg     0.8788    0.8760    0.8769       839

STARTING WITH FOLD NB 9

Epoch [1/5], Step [277/2770], Train Loss: 0.6964, Valid Loss: 0.5817
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_9/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_9/metrics/metrics.pth
Epoch [1/5], Step [554/2770], Train Loss: 0.4407, Valid Loss: 0.6390
Epoch [2/5], Step [831/2770], Train Loss: 0.2994, Valid Loss: 0.4308
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_9/model/model.pth
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_9/metrics/metrics.pth
Epoch [2/5], Step [1108/2770], Train Loss: 0.2542, Valid Loss: 0.4727
Epoch [3/5], Step [1385/2770], Train Loss: 0.1568, Valid Loss: 0.5307
Epoch [3/5], Step [1662/2770], Train Loss: 0.1391, Valid Loss: 0.4801
Epoch [4/5], Step [1939/2770], Train Loss: 0.0896, Valid Loss: 0.5360
Epoch [4/5], Step [2216/2770], Train Loss: 0.0781, Valid Loss: 0.5504
Epoch [5/5], Step [2493/2770], Train Loss: 0.0433, Valid Loss: 0.7782
Epoch [5/5], Step [2770/2770], Train Loss: 0.0530, Valid Loss: 0.6994
Model saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_9/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_9/metrics/metrics.pth
Model loaded from <== Temp_Data_Files/OverSampled/Dataset_KFold_9/model/model.pth
Pred saved to ==> Temp_Data_Files/OverSampled/Dataset_KFold_9/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           1     0.7270    0.9264    0.8147       299
           0     0.9520    0.8074    0.8737       540

    accuracy                         0.8498       839
   macro avg     0.8395    0.8669    0.8442       839
weighted avg     0.8718    0.8498    0.8527       839

