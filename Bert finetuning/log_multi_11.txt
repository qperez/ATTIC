Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 512). Running this sequence through the model will result in indexing errors
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Token indices sequence length is longer than the specified maximum sequence length for this model (2671 > 512). Running this sequence through the model will result in indexing errors
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Token indices sequence length is longer than the specified maximum sequence length for this model (2671 > 512). Running this sequence through the model will result in indexing errors
starting creation of datasets for cross validation
{'BUILD_SYSTEM': 0, 'BUG': 1, 'RFE': 2, 'IMPROVEMENT': 3, 'DOCUMENTATION': 4, 'TASK': 5, 'SPEC': 6, 'TEST': 7, 'UNKNOWN': 8, 'OTHER': 9, 'REFACTORING': 10, 'CLEANUP': 11, 'DESIGN_DEFECT': 12, 'BACKPORT': 13}
creating oversampled dataset of : (5591, 2)
starting creation of datasets for cross validation
{'BUILD_SYSTEM': 0, 'BUG': 1, 'RFE': 2, 'IMPROVEMENT': 3, 'DOCUMENTATION': 4, 'TASK': 5, 'SPEC': 6, 'TEST': 7, 'UNKNOWN': 8, 'OTHER': 9, 'REFACTORING': 10, 'CLEANUP': 11, 'DESIGN_DEFECT': 12, 'BACKPORT': 13}
creating dataset of : (5591, 2)
starting fine tuning
cuda:0
STARTING CROSS VALIDATION FOR NotSampled DATASET

STARTING WITH FOLD NB 0

Epoch [1/5], Step [214/2140], Train Loss: 1.8502, Valid Loss: 1.6047
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 1.5295, Valid Loss: 1.2403
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 1.0821, Valid Loss: 1.1658
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [2/5], Step [856/2140], Train Loss: 1.0137, Valid Loss: 1.0397
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [3/5], Step [1070/2140], Train Loss: 0.7370, Valid Loss: 1.0272
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [3/5], Step [1284/2140], Train Loss: 0.7417, Valid Loss: 0.9894
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/metrics/metrics.pth
Epoch [4/5], Step [1498/2140], Train Loss: 0.4936, Valid Loss: 1.0166
Epoch [4/5], Step [1712/2140], Train Loss: 0.5078, Valid Loss: 0.9954
Epoch [5/5], Step [1926/2140], Train Loss: 0.3200, Valid Loss: 1.0676
Epoch [5/5], Step [2140/2140], Train Loss: 0.3208, Valid Loss: 1.0530
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/metrics/metrics.pth
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/model/model.pth
Pred saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_0/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           0     0.4583    0.4583    0.4583        24
           1     0.8018    0.8796    0.8389       299
           2     0.6561    0.7518    0.7007       137
           3     0.7154    0.5706    0.6348       163
           4     0.7917    0.7917    0.7917        48
           5     0.0000    0.0000    0.0000         3
           6     0.0000    0.0000    0.0000         6
           7     0.7458    0.8302    0.7857        53
           8     0.0000    0.0000    0.0000         1
           9     0.0000    0.0000    0.0000         9
          10     0.4444    0.7273    0.5517        33
          11     0.5526    0.6176    0.5833        34
          12     0.0000    0.0000    0.0000        25
          13     0.0000    0.0000    0.0000         4

    accuracy                         0.7116       839
   macro avg     0.3690    0.4019    0.3818       839
weighted avg     0.6773    0.7116    0.6901       839

STARTING WITH FOLD NB 1

Epoch [1/5], Step [214/2140], Train Loss: 1.8676, Valid Loss: 1.5434
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 1.4567, Valid Loss: 1.1693
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 1.0922, Valid Loss: 1.0181
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [2/5], Step [856/2140], Train Loss: 0.9704, Valid Loss: 0.9853
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [3/5], Step [1070/2140], Train Loss: 0.7198, Valid Loss: 0.9752
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [3/5], Step [1284/2140], Train Loss: 0.6725, Valid Loss: 0.9270
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/metrics/metrics.pth
Epoch [4/5], Step [1498/2140], Train Loss: 0.4636, Valid Loss: 1.0356
Epoch [4/5], Step [1712/2140], Train Loss: 0.4418, Valid Loss: 1.0122
Epoch [5/5], Step [1926/2140], Train Loss: 0.2885, Valid Loss: 1.0937
Epoch [5/5], Step [2140/2140], Train Loss: 0.2995, Valid Loss: 1.0921
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/metrics/metrics.pth
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/model/model.pth
Pred saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_1/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           0     0.6000    0.5000    0.5455        24
           1     0.8063    0.8629    0.8336       299
           2     0.6340    0.7080    0.6690       137
           3     0.6408    0.5583    0.5967       163
           4     0.8261    0.7917    0.8085        48
           5     0.0000    0.0000    0.0000         3
           6     0.0000    0.0000    0.0000         6
           7     0.7213    0.8302    0.7719        53
           8     0.0000    0.0000    0.0000         1
           9     0.0000    0.0000    0.0000         9
          10     0.4259    0.6970    0.5287        33
          11     0.5135    0.5588    0.5352        34
          12     0.6667    0.1600    0.2581        25
          13     0.0000    0.0000    0.0000         4

    accuracy                         0.6985       839
   macro avg     0.4168    0.4048    0.3962       839
weighted avg     0.6828    0.6985    0.6830       839

STARTING WITH FOLD NB 2

Epoch [1/5], Step [214/2140], Train Loss: 1.8095, Valid Loss: 1.5002
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 1.4362, Valid Loss: 1.1470
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 1.0530, Valid Loss: 1.0075
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [2/5], Step [856/2140], Train Loss: 0.9525, Valid Loss: 0.9704
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [3/5], Step [1070/2140], Train Loss: 0.7015, Valid Loss: 0.9800
Epoch [3/5], Step [1284/2140], Train Loss: 0.6950, Valid Loss: 0.9481Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Token indices sequence length is longer than the specified maximum sequence length for this model (2671 > 512). Running this sequence through the model will result in indexing errors
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Token indices sequence length is longer than the specified maximum sequence length for this model (2671 > 512). Running this sequence through the model will result in indexing errors
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Token indices sequence length is longer than the specified maximum sequence length for this model (2671 > 512). Running this sequence through the model will result in indexing errors

Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_2/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_2/metrics/metrics.pth
Epoch [4/5], Step [1498/2140], Train Loss: 0.4337, Valid Loss: 1.0152
Epoch [4/5], Step [1712/2140], Train Loss: 0.4576, Valid Loss: 1.0044
Epoch [5/5], Step [1926/2140], Train Loss: 0.2787, Valid Loss: 1.1690
Epoch [5/5], Step [2140/2140], Train Loss: 0.2620, Valid Loss: 1.2593
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_2/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_2/metrics/metrics.pth
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_2/model/model.pth
Pred saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_2/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           0     0.7273    0.3333    0.4571        24
           1     0.8316    0.8261    0.8289       299
           2     0.6358    0.7007    0.6667       137
           3     0.5561    0.6994    0.6196       163
           4     0.8200    0.8542    0.8367        48
           5     0.0000    0.0000    0.0000         3
           6     0.0000    0.0000    0.0000         6
           7     0.7586    0.8302    0.7928        53
           8     0.0000    0.0000    0.0000         1
           9     0.0000    0.0000    0.0000         9
          10     0.6296    0.5152    0.5667        33
          11     0.5405    0.5882    0.5634        34
          12     0.6667    0.0800    0.1429        25
          13     0.0000    0.0000    0.0000         4

    accuracy                         0.7020       839
   macro avg     0.4404    0.3877    0.3910       839
weighted avg     0.6904    0.7020    0.6850       839

STARTING WITH FOLD NB 3

Epoch [1/5], Step [214/2140], Train Loss: 1.8920, Valid Loss: 1.7033
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 1.4956, Valid Loss: 1.3314
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 1.1213, Valid Loss: 1.1862
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [2/5], Step [856/2140], Train Loss: 1.0299, Valid Loss: 1.1032
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [3/5], Step [1070/2140], Train Loss: 0.7436, Valid Loss: 1.0157
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_3/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_3/metrics/metrics.pth
Epoch [3/5], Step [1284/2140], Train Loss: 0.7031, Valid Loss: 1.0173
Epoch [4/5], Step [1498/2140], Train Loss: 0.4753, Valid Loss: 1.0842
Epoch [4/5], Step [1712/2140], Train Loss: 0.4852, Valid Loss: 1.1042
Epoch [5/5], Step [1926/2140], Train Loss: 0.3208, Valid Loss: 1.1222
Epoch [5/5], Step [2140/2140], Train Loss: 0.3128, Valid Loss: 1.2588
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_3/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_3/metrics/metrics.pth
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_3/model/model.pth
Pred saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_3/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           0     0.5789    0.4583    0.5116        24
           1     0.7864    0.8863    0.8333       299
           2     0.6667    0.7007    0.6833       137
           3     0.6906    0.5890    0.6358       163
           4     0.6452    0.8333    0.7273        48
           5     0.0000    0.0000    0.0000         3
           6     0.0000    0.0000    0.0000         6
           7     0.8000    0.7547    0.7767        53
           8     0.0000    0.0000    0.0000         1
           9     0.0000    0.0000    0.0000         9
          10     0.4490    0.6667    0.5366        33
          11     0.5789    0.6471    0.6111        34
          12     1.0000    0.0400    0.0769        25
          13     0.0000    0.0000    0.0000         4

    accuracy                         0.7068       839
   macro avg     0.4425    0.3983    0.3852       839
weighted avg     0.6982    0.7068    0.6855       839

STARTING WITH FOLD NB 4

Epoch [1/5], Step [214/2140], Train Loss: 1.8282, Valid Loss: 1.6203
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 1.4597, Valid Loss: 1.2841
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 1.0618, Valid Loss: 1.1650
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [2/5], Step [856/2140], Train Loss: 0.9794, Valid Loss: 1.1069
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [3/5], Step [1070/2140], Train Loss: 0.7026, Valid Loss: 1.0488
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [3/5], Step [1284/2140], Train Loss: 0.6956, Valid Loss: 1.0102
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/metrics/metrics.pth
Epoch [4/5], Step [1498/2140], Train Loss: 0.4666, Valid Loss: 1.0585
Epoch [4/5], Step [1712/2140], Train Loss: 0.4713, Valid Loss: 1.1135
Epoch [5/5], Step [1926/2140], Train Loss: 0.3026, Valid Loss: 1.2082
Epoch [5/5], Step [2140/2140], Train Loss: 0.3081, Valid Loss: 1.1259
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/metrics/metrics.pth
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/model/model.pth
Pred saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_4/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           0     0.7000    0.2917    0.4118        24
           1     0.8101    0.8562    0.8325       299
           2     0.6095    0.7518    0.6732       137
           3     0.6322    0.6748    0.6528       163
           4     0.7222    0.8125    0.7647        48
           5     0.0000    0.0000    0.0000         3
           6     0.0000    0.0000    0.0000         6
           7     0.8163    0.7547    0.7843        53
           8     0.0000    0.0000    0.0000         1
           9     0.0000    0.0000    0.0000         9
          10     0.6061    0.6061    0.6061        33
          11     0.5588    0.5588    0.5588        34
          12     0.0000    0.0000    0.0000        25
          13     0.0000    0.0000    0.0000         4

    accuracy                         0.7080       839
   macro avg     0.3897    0.3790    0.3774       839
weighted avg     0.6704    0.7080    0.6850       839

STARTING WITH FOLD NB 5

Epoch [1/5], Step [214/2140], Train Loss: 1.7752, Valid Loss: 1.5465
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_5/model/model.pthSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Token indices sequence length is longer than the specified maximum sequence length for this model (2671 > 512). Running this sequence through the model will result in indexing errors
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Token indices sequence length is longer than the specified maximum sequence length for this model (2671 > 512). Running this sequence through the model will result in indexing errors
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 1.3455, Valid Loss: 1.2861
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_5/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 1.0000, Valid Loss: 1.1417
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_5/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [2/5], Step [856/2140], Train Loss: 0.9415, Valid Loss: 1.0681
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_5/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [3/5], Step [1070/2140], Train Loss: 0.6751, Valid Loss: 1.0610
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_5/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_5/metrics/metrics.pth
Epoch [3/5], Step [1284/2140], Train Loss: 0.6668, Valid Loss: 1.1460
Epoch [4/5], Step [1498/2140], Train Loss: 0.4146, Valid Loss: 1.1686
Epoch [4/5], Step [1712/2140], Train Loss: 0.4127, Valid Loss: 1.1864
Epoch [5/5], Step [1926/2140], Train Loss: 0.2601, Valid Loss: 1.2420
Epoch [5/5], Step [2140/2140], Train Loss: 0.2771, Valid Loss: 1.2947
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_5/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_5/metrics/metrics.pth
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_5/model/model.pth
Pred saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_5/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           0     0.4167    0.4167    0.4167        24
           1     0.8165    0.8629    0.8390       299
           2     0.5976    0.7153    0.6512       137
           3     0.6838    0.5706    0.6221       163
           4     0.7907    0.7083    0.7473        48
           5     0.0000    0.0000    0.0000         3
           6     0.0000    0.0000    0.0000         6
           7     0.7458    0.8302    0.7857        53
           8     0.0000    0.0000    0.0000         1
           9     0.0000    0.0000    0.0000         9
          10     0.4340    0.6970    0.5349        33
          11     0.5122    0.6176    0.5600        34
          12     0.6667    0.0800    0.1429        25
          13     0.0000    0.0000    0.0000         4

    accuracy                         0.6949       839
   macro avg     0.4046    0.3928    0.3785       839
weighted avg     0.6833    0.6949    0.6785       839

STARTING WITH FOLD NB 6

Epoch [1/5], Step [214/2140], Train Loss: 1.8757, Valid Loss: 1.5252
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_6/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_6/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 1.4175, Valid Loss: 1.1509
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_6/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_6/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 1.0249, Valid Loss: 1.1118
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_6/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_6/metrics/metrics.pth
Epoch [2/5], Step [856/2140], Train Loss: 1.0026, Valid Loss: 0.9990
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_6/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_6/metrics/metrics.pth
Epoch [3/5], Step [1070/2140], Train Loss: 0.6938, Valid Loss: 0.9543
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_6/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_6/metrics/metrics.pth
Epoch [3/5], Step [1284/2140], Train Loss: 0.6931, Valid Loss: 0.9902
Epoch [4/5], Step [1498/2140], Train Loss: 0.4465, Valid Loss: 1.0300
Epoch [4/5], Step [1712/2140], Train Loss: 0.4867, Valid Loss: 1.0744
Epoch [5/5], Step [1926/2140], Train Loss: 0.2869, Valid Loss: 1.1880
Epoch [5/5], Step [2140/2140], Train Loss: 0.3365, Valid Loss: 1.1556
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_6/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_6/metrics/metrics.pth
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_6/model/model.pth
Pred saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_6/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           0     0.4074    0.4583    0.4314        24
           1     0.8176    0.8395    0.8284       299
           2     0.6414    0.6788    0.6596       137
           3     0.6164    0.6012    0.6087       163
           4     0.7660    0.7500    0.7579        48
           5     0.0000    0.0000    0.0000         3
           6     0.0000    0.0000    0.0000         6
           7     0.6935    0.8113    0.7478        53
           8     0.0000    0.0000    0.0000         1
           9     0.0000    0.0000    0.0000         9
          10     0.4000    0.6667    0.5000        33
          11     0.5000    0.5294    0.5143        34
          12     1.0000    0.0400    0.0769        25
          13     0.0000    0.0000    0.0000         4

    accuracy                         0.6830       839
   macro avg     0.4173    0.3839    0.3661       839
weighted avg     0.6809    0.6830    0.6669       839

STARTING WITH FOLD NB 7

Epoch [1/5], Step [214/2140], Train Loss: 1.8696, Valid Loss: 1.4944
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_7/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 1.3476, Valid Loss: 1.1655
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_7/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 1.0380, Valid Loss: 1.0081
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_7/metrics/metrics.pth
Epoch [2/5], Step [856/2140], Train Loss: 0.9799, Valid Loss: 0.9848
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_7/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_7/metrics/metrics.pth
Epoch [3/5], Step [1070/2140], Train Loss: 0.6782, Valid Loss: 1.0058
Epoch [3/5], Step [1284/2140], Train Loss: 0.6840, Valid Loss: 1.0579
Epoch [4/5], Step [1498/2140], Train Loss: 0.4351, Valid Loss: 1.0809
Epoch [4/5], Step [1712/2140], Train Loss: 0.4570, Valid Loss: 1.0324
Epoch [5/5], Step [1926/2140], Train Loss: 0.2920, Valid Loss: 1.1885
Epoch [5/5], Step [2140/2140], Train Loss: 0.3319, Valid Loss: 1.1695
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_7/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_7/metrics/metrics.pth
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_7/model/model.pth
Pred saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_7/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           0     0.6000    0.3750    0.4615        24
           1     0.8121    0.8094    0.8107       299
           2     0.6714    0.6861    0.6787       137
           3     0.5507    0.6994    0.6162       163
           4     0.7037    0.7917    0.7451        48
           5     0.0000    0.0000    0.0000         3
           6     0.0000    0.0000    0.0000         6
           7     0.6923    0.8491    0.7627        53
           8     0.0000    0.0000    0.0000         1
           9     0.0000    0.0000    0.0000         9
          10     0.5862    0.5152    0.5484        33
          11     0.6452    0.5882    0.6154        34
          12     0.0000    0.0000    0.0000        25
          13     0.0000    0.0000    0.0000         4

    accuracy                         0.6901       839
   macro avg     0.3758    0.3796    0.3742       839
weighted avg     0.6564    0.6901    0.6700       839
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Token indices sequence length is longer than the specified maximum sequence length for this model (2671 > 512). Running this sequence through the model will result in indexing errors
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Token indices sequence length is longer than the specified maximum sequence length for this model (2671 > 512). Running this sequence through the model will result in indexing errors
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

STARTING WITH FOLD NB 8

Epoch [1/5], Step [214/2140], Train Loss: 1.8633, Valid Loss: 1.4869
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_8/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_8/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 1.3974, Valid Loss: 1.1993
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_8/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_8/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 1.0345, Valid Loss: 1.0004
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_8/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_8/metrics/metrics.pth
Epoch [2/5], Step [856/2140], Train Loss: 0.9927, Valid Loss: 0.9023
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_8/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_8/metrics/metrics.pth
Epoch [3/5], Step [1070/2140], Train Loss: 0.6573, Valid Loss: 0.9503
Epoch [3/5], Step [1284/2140], Train Loss: 0.6931, Valid Loss: 0.8737
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_8/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_8/metrics/metrics.pth
Epoch [4/5], Step [1498/2140], Train Loss: 0.4321, Valid Loss: 0.9724
Epoch [4/5], Step [1712/2140], Train Loss: 0.4306, Valid Loss: 0.9808
Epoch [5/5], Step [1926/2140], Train Loss: 0.2633, Valid Loss: 1.1110
Epoch [5/5], Step [2140/2140], Train Loss: 0.3085, Valid Loss: 1.0709
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_8/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_8/metrics/metrics.pth
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_8/model/model.pth
Pred saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_8/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           0     0.6842    0.5417    0.6047        24
           1     0.8196    0.8662    0.8423       299
           2     0.6096    0.8321    0.7037       137
           3     0.6603    0.6319    0.6458       163
           4     0.7917    0.7917    0.7917        48
           5     0.0000    0.0000    0.0000         3
           6     0.0000    0.0000    0.0000         6
           7     0.8000    0.6792    0.7347        53
           8     0.0000    0.0000    0.0000         1
           9     0.0000    0.0000    0.0000         9
          10     0.6364    0.6364    0.6364        33
          11     0.5882    0.5882    0.5882        34
          12     1.0000    0.0400    0.0769        25
          13     0.0000    0.0000    0.0000         4

    accuracy                         0.7211       839
   macro avg     0.4707    0.4005    0.4017       839
weighted avg     0.7140    0.7211    0.7007       839

STARTING WITH FOLD NB 9

Epoch [1/5], Step [214/2140], Train Loss: 1.9847, Valid Loss: 2.0083
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/metrics/metrics.pth
Epoch [1/5], Step [428/2140], Train Loss: 1.6890, Valid Loss: 1.7581
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/metrics/metrics.pth
Epoch [2/5], Step [642/2140], Train Loss: 1.2897, Valid Loss: 1.4588
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/metrics/metrics.pth
Epoch [2/5], Step [856/2140], Train Loss: 1.1084, Valid Loss: 1.2321
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/metrics/metrics.pth
Epoch [3/5], Step [1070/2140], Train Loss: 0.7761, Valid Loss: 1.2446
Epoch [3/5], Step [1284/2140], Train Loss: 0.7738, Valid Loss: 1.2192
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/metrics/metrics.pth
Epoch [4/5], Step [1498/2140], Train Loss: 0.5437, Valid Loss: 1.1970
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/model/model.pth
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/metrics/metrics.pth
Epoch [4/5], Step [1712/2140], Train Loss: 0.5165, Valid Loss: 1.2144
Epoch [5/5], Step [1926/2140], Train Loss: 0.3256, Valid Loss: 1.2134
Epoch [5/5], Step [2140/2140], Train Loss: 0.3648, Valid Loss: 1.3855
Model saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/metrics/metrics.pth
Finished Training!
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/metrics/metrics.pth
Model loaded from <== Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/model/model.pth
Pred saved to ==> Temp_Data_Files_Multiclass/NotSampled/Dataset_KFold_9/evaluate/evaluate.pth
Classification Report :
              precision    recall  f1-score   support

           0     0.6667    0.8333    0.7407        24
           1     0.8655    0.7960    0.8293       299
           2     0.6159    0.7372    0.6711       137
           3     0.6059    0.6319    0.6186       163
           4     0.7037    0.7917    0.7451        48
           5     0.0000    0.0000    0.0000         3
           6     0.0000    0.0000    0.0000         6
           7     0.6400    0.9057    0.7500        53
           8     0.0000    0.0000    0.0000         1
           9     0.0000    0.0000    0.0000         9
          10     0.5946    0.6667    0.6286        33
          11     0.6552    0.5588    0.6032        34
          12     0.4000    0.0800    0.1333        25
          13     0.0000    0.0000    0.0000         4

    accuracy                         0.7044       839
   macro avg     0.4105    0.4287    0.4086       839
weighted avg     0.6883    0.7044    0.6896       839

